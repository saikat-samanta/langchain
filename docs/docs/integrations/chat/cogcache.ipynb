{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "sidebar_label: CogCache\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CogCache\n",
    "\n",
    "This notebook shows how to use LangChain with CogCache [chat models](/docs/concepts/#chat-models). For detailed documentation of all ChatCogCache features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/chat_models/langchain_community.chat_models.cogcache.ChatCogCache.html).\n",
    "\n",
    "CogCache has several chat models. You can find information about their latest models and their costs, context windows, and supported input types in the [CogCache docs](https://cogcache.readme.io/reference/models).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"COGCACHE_API_KEY\"):\n",
    "    os.environ[\"COGCACHE_API_KEY\"] = getpass.getpass(\"Enter your CogCache API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "The LangChain CogCache integration lives in the `langchain` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "Now we can instantiate our model object and generate chat completions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatCogCache\n",
    "\n",
    "llm = ChatCogCache(\n",
    "    api_key=\"YOUR_API_KEY\",\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    # temperature=0,\n",
    "    # max_tokens=None,\n",
    "    # n=1,\n",
    "    # verbose=True,\n",
    "    # timeout=None,\n",
    "    # model_kwargs={ \"response_format\": { \"type\": \"json_object\" } }\n",
    "    # default_headers={\"Cache-Control\": \"no-store\"} \n",
    "    # ...\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'aime la programmation.\", response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 31, 'total_tokens': 38}, 'model_name': 'gpt-4-1106-preview', 'system_fingerprint': 'fp_5603ee5e2e', 'finish_reason': 'stop', 'logprobs': None}, id='run-c801654f-d8f7-4cb8-aa86-82019e0d844d-0', kwargs={'choices': [{'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}, 'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': \"J'aime la programmation.\", 'role': 'assistant'}}], 'created': 1727347241, 'id': 'chatcmpl-ABgDJIg9HLpduHwGJ22p6JtiWueGF', 'model': 'gpt-4', 'object': 'chat.completion', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'system_fingerprint': 'fp_5603ee5e2e', 'usage': {'completion_tokens': 7, 'prompt_tokens': 31, 'total_tokens': 38}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' response_metadata={'model_name': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e'} id='run-d7165258-d752-405d-ab27-2269f65a3b7a' kwargs={'id': 'chatcmpl-ABgDJIg9HLpduHwGJ22p6JtiWueGF', 'object': 'chat.completion.chunk', 'created': 1727347241, 'model': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'choices': [{'index': 0, 'delta': {'role': 'assistant', 'content': ''}, 'finish_reason': ''}]}\n",
      "content='J' response_metadata={'model_name': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e'} id='run-d7165258-d752-405d-ab27-2269f65a3b7a' kwargs={'id': 'chatcmpl-ABgDJIg9HLpduHwGJ22p6JtiWueGF', 'object': 'chat.completion.chunk', 'created': 1727347241, 'model': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'choices': [{'index': 0, 'delta': {'content': 'J'}, 'finish_reason': ''}]}\n",
      "content=\"'\" response_metadata={'model_name': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e'} id='run-d7165258-d752-405d-ab27-2269f65a3b7a' kwargs={'id': 'chatcmpl-ABgDJIg9HLpduHwGJ22p6JtiWueGF', 'object': 'chat.completion.chunk', 'created': 1727347241, 'model': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'choices': [{'index': 0, 'delta': {'content': \"'\"}, 'finish_reason': ''}]}\n",
      "content='aime' response_metadata={'model_name': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e'} id='run-d7165258-d752-405d-ab27-2269f65a3b7a' kwargs={'id': 'chatcmpl-ABgDJIg9HLpduHwGJ22p6JtiWueGF', 'object': 'chat.completion.chunk', 'created': 1727347241, 'model': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'choices': [{'index': 0, 'delta': {'content': 'aime'}, 'finish_reason': ''}]}\n",
      "content=' ' response_metadata={'model_name': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e'} id='run-d7165258-d752-405d-ab27-2269f65a3b7a' kwargs={'id': 'chatcmpl-ABgDJIg9HLpduHwGJ22p6JtiWueGF', 'object': 'chat.completion.chunk', 'created': 1727347241, 'model': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'choices': [{'index': 0, 'delta': {'content': ' '}, 'finish_reason': ''}]}\n",
      "content='la' response_metadata={'model_name': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e'} id='run-d7165258-d752-405d-ab27-2269f65a3b7a' kwargs={'id': 'chatcmpl-ABgDJIg9HLpduHwGJ22p6JtiWueGF', 'object': 'chat.completion.chunk', 'created': 1727347241, 'model': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'choices': [{'index': 0, 'delta': {'content': 'la'}, 'finish_reason': ''}]}\n",
      "content=' ' response_metadata={'model_name': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e'} id='run-d7165258-d752-405d-ab27-2269f65a3b7a' kwargs={'id': 'chatcmpl-ABgDJIg9HLpduHwGJ22p6JtiWueGF', 'object': 'chat.completion.chunk', 'created': 1727347241, 'model': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'choices': [{'index': 0, 'delta': {'content': ' '}, 'finish_reason': ''}]}\n",
      "content='programmation' response_metadata={'model_name': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e'} id='run-d7165258-d752-405d-ab27-2269f65a3b7a' kwargs={'id': 'chatcmpl-ABgDJIg9HLpduHwGJ22p6JtiWueGF', 'object': 'chat.completion.chunk', 'created': 1727347241, 'model': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'choices': [{'index': 0, 'delta': {'content': 'programmation'}, 'finish_reason': ''}]}\n",
      "content='.' response_metadata={'model_name': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e'} id='run-d7165258-d752-405d-ab27-2269f65a3b7a' kwargs={'id': 'chatcmpl-ABgDJIg9HLpduHwGJ22p6JtiWueGF', 'object': 'chat.completion.chunk', 'created': 1727347241, 'model': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'choices': [{'index': 0, 'delta': {'content': '.'}, 'finish_reason': ''}]}\n",
      "content='' response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e'} id='run-d7165258-d752-405d-ab27-2269f65a3b7a' kwargs={'id': 'chatcmpl-ABgDJIg9HLpduHwGJ22p6JtiWueGF', 'object': 'chat.completion.chunk', 'created': 1727347241, 'model': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'choices': [{'index': 0, 'delta': {}, 'finish_reason': 'stop'}]}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_stream = llm.stream(messages)\n",
    "\n",
    "for ai_msg in ai_stream:\n",
    "    print(ai_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J'aime la programmation.\n"
     ]
    }
   ],
   "source": [
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "We can [chain](/docs/how_to/sequence/) our model with a prompt template like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Estoy escribiendo en español. Me encanta programar.', response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 31, 'total_tokens': 45}, 'model_name': 'gpt-4-1106-preview', 'system_fingerprint': 'fp_5603ee5e2e', 'finish_reason': 'stop', 'logprobs': None}, id='run-b26f7811-c618-4397-b808-135069cc29b1-0', kwargs={'choices': [{'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}, 'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': 'Estoy escribiendo en español. Me encanta programar.', 'role': 'assistant'}}], 'created': 1727347389, 'id': 'chatcmpl-ABgFhzc3DcSsnhjSbvu867av969GV', 'model': 'gpt-4', 'object': 'chat.completion', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'system_fingerprint': 'fp_5603ee5e2e', 'usage': {'completion_tokens': 14, 'prompt_tokens': 31, 'total_tokens': 45}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"Spanish\",\n",
    "        \"input\": \"I am writing spanish. I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Headers\n",
    "\n",
    "We can access response headers directly with prompt invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': 'Fri, 27 Sep 2024 11:04:42 GMT',\n",
       " 'server': 'uvicorn',\n",
       " 'x-cache': 'hit',\n",
       " 'access-control-allow-origin': '*',\n",
       " 'access-control-allow-credentials': 'true',\n",
       " 'access-control-expose-headers': 'content-type,x-cache,cogcache-hit-type,cogcache-similarity-match-score,cogcache-hit-processing-ms,cogcache-latency-ms',\n",
       " 'access-control-allow-methods': 'GET, OPTIONS, POST',\n",
       " 'access-control-max-age': '600',\n",
       " 'vary': 'Origin',\n",
       " 'cogcache-hit-type': 'exact-match',\n",
       " 'cogcache-prompt-type': 'other',\n",
       " 'cogcache-cache-entry-id': 'b14b8f518b54e4ef2187972f217dacc0',\n",
       " 'content-length': '894',\n",
       " 'content-type': 'application/json',\n",
       " 'cogcache-hit-processing-ms': '0.81',\n",
       " 'cogcache-latency-ms': '1.05'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatCogCache\n",
    "\n",
    "llm = ChatCogCache(\n",
    "    api_key=\"YOUR_API_KEY\",\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    include_response_headers=True,  # set to True to include headers in the response\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "response = llm.invoke(messages)\n",
    "response.response_metadata[\"headers\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add parameters in individual invocation\n",
    "\n",
    "Instead of putting all parameters during class instantiation. We can pass parameters in individual invocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'aime la programmation.\", response_metadata={'token_usage': {'prompt_tokens': 31, 'completion_tokens': 7, 'total_tokens': 38}, 'model_name': 'gpt-35-turbo-0125', 'system_fingerprint': 'fp_5603ee5e2e', 'finish_reason': 'stop', 'logprobs': None}, id='run-a5f3d2b5-480f-4127-bc9f-891d28745761-0', kwargs={'id': 'chatcmpl-ABgDJIg9HLpduHwGJ22p6JtiWueGF', 'object': 'chat.completion', 'created': 1727347241, 'model': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e', 'choices': [{'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}, 'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': \"J'aime la programmation.\", 'role': 'assistant'}}], 'usage': {'prompt_tokens': 31, 'completion_tokens': 7, 'total_tokens': 38}, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}]})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatCogCache\n",
    "\n",
    "llm = ChatCogCache(\n",
    "    api_key=\"YOUR_API_KEY\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "llm.invoke(\n",
    "    messages,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    # temperature=0,\n",
    "    # max_tokens=None,\n",
    "    # n=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all CogCache features and configurations head to the API reference: https://cogcache.readme.io/reference/overview"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
